<h1>This repository provides the <strong>PyTorch implementation</strong> of our work <strong>GEOBench-VLM: Benchmarking Vision-Language Models for Geospatial Tasks</strong>.</h1>

ðŸ”— Access and set up the following vision-language models: [Qwen2.5-VL (QwenLM)](https://github.com/QwenLM/Qwen2.5-VL), [InternVL2 (OpenGVLab)](https://github.com/OpenGVLab/InternVL), [LLaVA 1.5 / 1.6 (haotian-liu)](https://github.com/haotian-liu/LLaVA), and [LLaVA-OneVision (LLaVA-VL)](https://github.com/LLaVA-VL/LLaVA-NeXT). Each repository includes environment setup instructions.
